sims |>
ggplot(aes(x=week,y=reports,group=.id,color=.id=="data"))+
geom_line()+
guides(color="none")+
ggtitle("Simulations of SEIR")
# generate simulations based on the parameter values we choose:
measSEIR |>
simulate(
params=c(Beta=30,mu_EI=0.8,mu_IR=1,rho=0.5,k=10,
eta=0.05,N=38000),
nsim=20,format="data.frame",include.data=TRUE
) -> sims
# plot the simulations
sims |>
ggplot(aes(x=week,y=reports,group=.id,color=.id=="data"))+
geom_line()+
guides(color="none")+
ggtitle("Simulations of SEIR")
library(doParallel)
cores <-  as.numeric(Sys.getenv('SLURM_NTASKS_PER_NODE', unset=NA))
if(is.na(cores)) cores <- detectCores()
registerDoParallel(cores)
system.time(
rnorm(10^8)
) -> time0
system.time(
foreach(i=1:10) %dopar% rnorm(10^7)
) -> time1
system.time(
foreach(i=1:10^2) %dopar% rnorm(10^6)
) -> time2
system.time(
foreach(i=1:10^3) %dopar% rnorm(10^5)
) -> time3
system.time(
foreach(i=1:10^4) %dopar% rnorm(10^4)
) -> time4
write.table(file="test.csv",
rbind(time0,time1,time2,time3,time4))
time1 <= read.csv("test.csv")
time1 <= read.csv("~/Library/Mobile Documents/com~apple~CloudDocs/531/Stats531/test.csv")
time1 <- read.csv("~/Library/Mobile Documents/com~apple~CloudDocs/531/Stats531/test.csv")
time1 <- read.csv("~/Library/Mobile Documents/com~apple~CloudDocs/531/Stats531/test.csv", sep = " ")
time1 <- read.csv("~/Library/Mobile Documents/com~apple~CloudDocs/531/Stats531/test.csv", sep = " ")
kable(temp_aic_table,digits=2)
library(kable)
library(knitr)
time1 <- read.csv("~/Library/Mobile Documents/com~apple~CloudDocs/531/Stats531/test.csv", sep = " ")
kable(temp_aic_table,digits=2)
require(knitr)
time1 <- read.csv("~/Library/Mobile Documents/com~apple~CloudDocs/531/Stats531/test.csv", sep = " ")
kable(time1)
time1
require(knitr)
time1 <- read.csv("~/Library/Mobile Documents/com~apple~CloudDocs/531/Stats531/greatlakes/test_local.csv", sep = " ")
kable(time1)
time2 <- read.csv("~/Library/Mobile Documents/com~apple~CloudDocs/531/Stats531/greatlakes/test_remote.csv", sep = " ")
kable(time2)
library(tidyverse)
library(pomp)
set.seed(1350254336)
source("https://kingaa.github.io/sbied/pfilter/model.R")
# step function: E is similar to the component I, add E in the chain
seir_step <- Csnippet("
double dN_SE = rbinom(S,1-exp(-Beta*I/N*dt));
double dN_EI = rbinom(E,1-exp(-mu_EI*dt));
double dN_IR = rbinom(I,1-exp(-mu_IR*dt));
S -= dN_SE;
E += dN_SE - dN_EI;
I += dN_EI - dN_IR;
R += dN_IR;
H += dN_IR;
")
# initial function: suppose we do not no the latent value of E at first.
seir_rinit <- Csnippet("
S = nearbyint(eta*N);
E = 0;
I = 1;
R = nearbyint((1-eta)*N);
H = 0;
")
# dmeasure component
seir_dmeas <- Csnippet("
lik = dnbinom_mu(reports,k,rho*H,give_log);
")
# rmeasure component
seir_rmeas <- Csnippet("
reports = rnbinom_mu(k,rho*H);
")
# add components to pomp model: clarify E and mu_EI
meas |>
pomp(times="week",t0=0,
rprocess=euler(seir_step,delta.t=1/7),
rinit=seir_rinit,
rmeasure=seir_rmeas,
dmeasure=seir_dmeas,
accumvars="H",
statenames=c("S","E","I","R","H"),
paramnames=c("Beta","mu_EI","mu_IR","N","eta","rho","k")
) -> measSEIR
rm(list = ls())
# step function: E is similar to the component I, add E in the chain
seir_step <- Csnippet("
double dN_SE = rbinom(S,1-exp(-Beta*I/N*dt));
double dN_EI = rbinom(E,1-exp(-mu_EI*dt));
double dN_IR = rbinom(I,1-exp(-mu_IR*dt));
S -= dN_SE;
E += dN_SE - dN_EI;
I += dN_EI - dN_IR;
R += dN_IR;
H += dN_IR;
")
# initial function: suppose we do not no the latent value of E at first.
seir_rinit <- Csnippet("
S = nearbyint(eta*N);
E = 0;
I = 1;
R = nearbyint((1-eta)*N);
H = 0;
")
# dmeasure component
seir_dmeas <- Csnippet("
lik = dnbinom_mu(reports,k,rho*H,give_log);
")
# rmeasure component
seir_rmeas <- Csnippet("
reports = rnbinom_mu(k,rho*H);
")
# add components to pomp model: clarify E and mu_EI
meas |>
pomp(times="week",t0=0,
rprocess=euler(seir_step,delta.t=1/7),
rinit=seir_rinit,
rmeasure=seir_rmeas,
dmeasure=seir_dmeas,
accumvars="H",
statenames=c("S","E","I","R","H"),
paramnames=c("Beta","mu_EI","mu_IR","N","eta","rho","k")
) -> measSEIR
# implement the SIR model in pomp
library(pomp)
# basic pomp model
meas |>
pomp(times="week",t0=0,
rprocess=euler(sir_step,delta.t=1/7),
rinit=sir_rinit, accumvars="H"
) -> measSIR
# load the data
library(tidyverse)
library(ggplot2)
read_csv(paste0("https://kingaa.github.io/sbied/stochsim/",
"Measles_Consett_1948.csv")) |>
select(week,reports=cases) -> meas
# implement the SIR model in pomp
library(pomp)
# step function: E is similar to the component I, add E in the chain
seir_step <- Csnippet("
double dN_SE = rbinom(S,1-exp(-Beta*I/N*dt));
double dN_EI = rbinom(E,1-exp(-mu_EI*dt));
double dN_IR = rbinom(I,1-exp(-mu_IR*dt));
S -= dN_SE;
E += dN_SE - dN_EI;
I += dN_EI - dN_IR;
R += dN_IR;
H += dN_IR;
")
# initial function: suppose we do not no the latent value of E at first.
seir_rinit <- Csnippet("
S = nearbyint(eta*N);
E = 0;
I = 1;
R = nearbyint((1-eta)*N);
H = 0;
")
# dmeasure component
seir_dmeas <- Csnippet("
lik = dnbinom_mu(reports,k,rho*H,give_log);
")
# rmeasure component
seir_rmeas <- Csnippet("
reports = rnbinom_mu(k,rho*H);
")
# add components to pomp model: clarify E and mu_EI
meas |>
pomp(times="week",t0=0,
rprocess=euler(seir_step,delta.t=1/7),
rinit=seir_rinit,
rmeasure=seir_rmeas,
dmeasure=seir_dmeas,
accumvars="H",
statenames=c("S","E","I","R","H"),
paramnames=c("Beta","mu_EI","mu_IR","N","eta","rho","k")
) -> measSEIR
# load the data
library(tidyverse)
library(ggplot2)
read_csv(paste0("https://kingaa.github.io/sbied/stochsim/",
"Measles_Consett_1948.csv")) |>
select(week,reports=cases) -> meas
# implement the SIR model in pomp
library(pomp)
# step function: E is similar to the component I, add E in the chain
seir_step <- Csnippet("
double dN_SE = rbinom(S,1-exp(-Beta*I/N*dt));
double dN_EI = rbinom(E,1-exp(-mu_EI*dt));
double dN_IR = rbinom(I,1-exp(-mu_IR*dt));
S -= dN_SE;
E += dN_SE - dN_EI;
I += dN_EI - dN_IR;
R += dN_IR;
H += dN_IR;
")
# initial function: suppose we do not no the latent value of E at first.
seir_rinit <- Csnippet("
S = nearbyint(eta*N);
E = 0;
I = 1;
R = nearbyint((1-eta)*N);
H = 0;
")
# dmeasure component
seir_dmeas <- Csnippet("
lik = dnbinom_mu(reports,k,rho*H,give_log);
")
# rmeasure component
seir_rmeas <- Csnippet("
reports = rnbinom_mu(k,rho*H);
")
# add components to pomp model: clarify E and mu_EI
meas |>
pomp(times="week",t0=0,
rprocess=euler(seir_step,delta.t=1/7),
rinit=seir_rinit,
rmeasure=seir_rmeas,
dmeasure=seir_dmeas,
accumvars="H",
statenames=c("S","E","I","R","H"),
paramnames=c("Beta","mu_EI","mu_IR","N","eta","rho","k")
) -> measSEIR
measSEIR |>
pfilter(Np = 1000) -> pf
read.csv("https://raw.githubusercontent.com/LiangqiTang/Stats-503/main/datasets/auto.csv?token=GHSAT0AAAAAACQJM3JUTMQFTTTCDMAZCITAZQMX64Q")
a = read.csv("https://raw.githubusercontent.com/LiangqiTang/Stats-503/main/datasets/auto.csv?token=GHSAT0AAAAAACQJM3JUTMQFTTTCDMAZCITAZQMX64Q")
a = read.csv("https://raw.githubusercontent.com/LiangqiTang/Stats-503/main/datasets/auto.csv")
rm(a)
# load the data
library(tidyverse)
library(ggplot2)
read_csv(paste0("https://kingaa.github.io/sbied/stochsim/",
"Measles_Consett_1948.csv")) |>
select(week,reports=cases) -> meas
# implement the SIR model in pomp
library(pomp)
# step function: E is similar to the component I, add E in the chain
seir_step <- Csnippet("
double dN_SE = rbinom(S,1-exp(-Beta*I/N*dt));
double dN_EI = rbinom(E,1-exp(-mu_EI*dt));
double dN_IR = rbinom(I,1-exp(-mu_IR*dt));
S -= dN_SE;
E += dN_SE - dN_EI;
I += dN_EI - dN_IR;
R += dN_IR;
H += dN_IR;
")
# initial function: suppose we do not no the latent value of E at first.
seir_rinit <- Csnippet("
S = nearbyint(eta*N);
E = 0;
I = 1;
R = nearbyint((1-eta)*N);
H = 0;
")
# dmeasure component
seir_dmeas <- Csnippet("
lik = dnbinom_mu(reports,k,rho*H,give_log);
")
# rmeasure component
seir_rmeas <- Csnippet("
reports = rnbinom_mu(k,rho*H);
")
# add components to pomp model: clarify E and mu_EI
meas |>
pomp(times="week",t0=0,
rprocess=euler(seir_step,delta.t=1/7),
rinit=seir_rinit,
rmeasure=seir_rmeas,
dmeasure=seir_dmeas,
accumvars="H",
statenames=c("S","E","I","R","H"),
paramnames=c("Beta","mu_EI","mu_IR","N","eta","rho","k"),
params=c(Beta=30,mu_EI=0.8,mu_IR=1,rho=0.5,k=10,eta=0.05,N=38000)
) -> measSEIR
measSEIR |>
pfilter(Np = 1000) -> pf
plot(pf)
fixed_params <- c(N=38000, mu_IR=2, k=10)
coef(measSEIR, names(fixed_params)) <- fixed_params
fixed_params <- c(N=38000, mu_IR=2, k=10)
coef(measSEIR, names(fixed_params)) <- fixed_params
library(foreach)
library(doFuture)
plan(multisession)
library(foreach)
library(doFuture)
plan(multisession)
fixed_params <- c(N=38000, mu_EI=1, mu_IR=2, k=10) # here I additionally fix mu_EI=1
coef(measSEIR, names(fixed_params)) <- fixed_params
fixed_params <- c(N=38000, mu_EI=1, mu_IR=2, k=10) # here I additionally fix mu_EI=1
coef(measSEIR, names(fixed_params)) <- fixed_params
library(foreach)
library(doFuture)
plan(multisession)
fixed_params <- c(N=38000, mu_EI=1.5, mu_IR=2, k=10) # here I additionally fix mu_EI=1.5
coef(measSEIR, names(fixed_params)) <- fixed_params
library(foreach)
library(doFuture)
plan(multisession)
# do local search
foreach(i=1:20,.combine=c,
.options.future=list(seed=482947940)
) %dofuture% {
measSIR |>
mif2(
Np=2000, Nmif=50,
cooling.fraction.50=0.5,
rw.sd=rw_sd(Beta=0.02, rho=0.02, eta=ivp(0.02)),
partrans=parameter_trans(log="Beta",logit=c("rho","eta")),
paramnames=c("Beta","rho","eta")
)
} -> mifs_local
# do local search
foreach(i=1:20,.combine=c,
.options.future=list(seed=482947940)
) %dofuture% {
measSEIR |>
mif2(
Np=2000, Nmif=50,
cooling.fraction.50=0.5,
rw.sd=rw_sd(Beta=0.02, rho=0.02, eta=ivp(0.02)),
partrans=parameter_trans(log="Beta",logit=c("rho","eta")),
paramnames=c("Beta","rho","eta")
)
} -> mifs_local
# Iterated filtering diagnostics
mifs_local |>
traces() |>
melt() |>
ggplot(aes(x=iteration,y=value,group=.L1,color=factor(.L1)))+
geom_line()+
guides(color="none")+
facet_wrap(~name,scales="free_y")
# running a particle filter
foreach(i=1:10,.combine=c,
.options.future=list(seed=TRUE)
) %dofuture% {
measSIR |> pfilter(Np=5000)
} -> pf
# running a particle filter
foreach(i=1:10,.combine=c,
.options.future=list(seed=TRUE)
) %dofuture% {
measSEIR |> pfilter(Np=5000)
} -> pf
pf |> logLik() |> logmeanexp(se=TRUE) -> L_pf
L_pf
pf[[1]] |> coef() |> bind_rows() |>
bind_cols(loglik=L_pf[1],loglik.se=L_pf[2]) |>
write_csv("measles_params.csv")
# do local search
foreach(i=1:20,.combine=c,
.options.future=list(seed=482947940)
) %dofuture% {
measSEIR |>
mif2(
Np=2000, Nmif=50,
cooling.fraction.50=0.5,
rw.sd=rw_sd(Beta=0.02, rho=0.02, eta=ivp(0.02)),
partrans=parameter_trans(log="Beta",logit=c("rho","eta")),
paramnames=c("Beta","rho","eta")
)
} -> mifs_local
# Iterated filtering diagnostics
mifs_local |>
traces() |>
melt() |>
ggplot(aes(x=iteration,y=value,group=.L1,color=factor(.L1)))+
geom_line()+
guides(color="none")+
facet_wrap(~name,scales="free_y")
# estimating the likelihood
foreach(mf=mifs_local,.combine=rbind,
.options.future=list(seed=900242057)
) %dofuture% {
evals <- replicate(10, logLik(pfilter(mf,Np=5000)))
ll <- logmeanexp(evals,se=TRUE)
mf |> coef() |> bind_rows() |>
bind_cols(loglik=ll[1],loglik.se=ll[2])
} -> results
pairs(~loglik+Beta+eta+rho,data=results,pch=16)
# build up a picture of the likelihood surface
read_csv("measles_params.csv") |>
bind_rows(results) |>
arrange(-loglik) |>
write_csv("measles_params.csv")
# build up a picture of the likelihood surface
read_csv("measles_params.csv") |>
bind_rows(results) |>
arrange(-loglik) |>
write_csv("measles_params.csv")
set.seed(2062379496)
runif_design(
lower=c(Beta=5,rho=0.2,eta=0),
upper=c(Beta=80,rho=0.9,eta=1),
nseq=400
) -> guesses
mf1 <- mifs_local[[1]]
foreach(guess=iter(guesses,"row"), .combine=rbind,
.options.future=list(seed=1270401374)
) %dofuture% {
mf1 |>
mif2(params=c(guess,fixed_params)) |>
mif2(Nmif=100) -> mf
replicate(
10,
mf |> pfilter(Np=5000) |> logLik()
) |>
logmeanexp(se=TRUE) -> ll
mf |> coef() |> bind_rows() |>
bind_cols(loglik=ll[1],loglik.se=ll[2])
} -> results
library(iterators)
set.seed(2062379496)
runif_design(
lower=c(Beta=5,rho=0.2,eta=0),
upper=c(Beta=80,rho=0.9,eta=1),
nseq=400
) -> guesses
mf1 <- mifs_local[[1]]
library(iterators)
foreach(guess=iter(guesses,"row"), .combine=rbind,
.options.future=list(seed=1270401374)
) %dofuture% {
mf1 |>
mif2(params=c(guess,fixed_params)) |>
mif2(Nmif=100) -> mf
replicate(
10,
mf |> pfilter(Np=5000) |> logLik()
) |>
logmeanexp(se=TRUE) -> ll
mf |> coef() |> bind_rows() |>
bind_cols(loglik=ll[1],loglik.se=ll[2])
} -> results
library(iterators)
foreach(guess=iter(guesses,"row"), .combine=rbind,
.options.future=list(seed=1270401374)
) %dofuture% {
mf1 |>
mif2(params=c(guess,fixed_params)) |>
mif2(Nmif=100) -> mf
replicate(
10,
mf |> pfilter(Np=2000) |> logLik()
) |>
logmeanexp(se=TRUE) -> ll
mf |> coef() |> bind_rows() |>
bind_cols(loglik=ll[1],loglik.se=ll[2])
} -> results
library(iterators)
foreach(guess=iter(guesses,"row"), .combine=rbind,
.options.future=list(seed=1270401374)
) %dofuture% {
mf1 |>
mif2(params=c(guess,fixed_params)) |>
mif2(Nmif=50) -> mf # change Nmif from 100 to 50
replicate(
10,
mf |> pfilter(Np=2000) |> logLik() # change Np from 5000 to 2000
) |>
logmeanexp(se=TRUE) -> ll
mf |> coef() |> bind_rows() |>
bind_cols(loglik=ll[1],loglik.se=ll[2])
} -> results
set.seed(2062379496)
runif_design(
lower=c(Beta=5,rho=0.2,eta=0),
upper=c(Beta=80,rho=0.9,eta=1),
nseq=100
) -> guesses
mf1 <- mifs_local[[1]]
set.seed(2062379496)
runif_design(
lower=c(Beta=5,rho=0.2,eta=0),
upper=c(Beta=80,rho=0.9,eta=1),
nseq=100 # change from 400 to 100
) -> guesses
mf1 <- mifs_local[[1]]
library(iterators)
foreach(guess=iter(guesses,"row"), .combine=rbind,
.options.future=list(seed=1270401374)
) %dofuture% {
mf1 |>
mif2(params=c(guess,fixed_params)) |>
mif2(Nmif=50) -> mf # change Nmif from 100 to 50
replicate(
10,
mf |> pfilter(Np=2000) |> logLik() # change Np from 5000 to 2000
) |>
logmeanexp(se=TRUE) -> ll
mf |> coef() |> bind_rows() |>
bind_cols(loglik=ll[1],loglik.se=ll[2])
} -> results
